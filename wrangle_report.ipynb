{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Onuorji Doris**\n",
    "\n",
    "\n",
    "In this report, I gathered, assessed and clean three datasets required for the analysis of WerateDogs which I scrapped from the twitter website. Below are the steps i took to gather, assess and clean the datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering \n",
    "\n",
    "I gathered data from three different sources and stored the three in separate files\n",
    "The three files are :\n",
    "- WerateDogs Twitter Enhanced archive which was already provided by Udacity. I manually imported the csv file into my workspace using the pandas.read command\n",
    "- The second dataset I used was also extracted by Udacity Neural network on Udacity server was downloaded by useing the get request command\n",
    "- The entire set of each tweet Json data was downloaded using the Twitter API using the twitter library tweepy. The retweet_count and favorite_count were extracted respectively from the twitter website.\n",
    "\n",
    "\n",
    "- I loaded the three datasets into my work space with namely df1,df2,df3 resectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I accessed my three dataframes **df1, df2,df3**, using both visual assesment and Programmatic assessment.\n",
    "The twitter_enhanced_csv data set(df1) : contains 2354 rows and 17 columns\n",
    "The image_prediction dataset (df2): contains 2075 rows and 12 columns \n",
    "The tweet_json dataset (df3): contains 2327rows and 3 columns \n",
    "\n",
    "- I observed visualy that the retweeted_status_id,in_reply_to_status_id columns contains numerous numbers of null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter_enhanced_archives\n",
    "\n",
    "- Erroneous datatypes in timestamp, extract year, month and day from timestamp\n",
    "- There are 104 data in the name column that does not have the actual dog names \n",
    "- There are 775 tweets with the dog name as 'None'\n",
    "- Delete columns that won't be needed for analysis\n",
    "- keep original tweets remove all retweets\n",
    "- There are only 4 types of values in the source column (Twitter for iphone,Vine,Twitter Web client and TweetDeck)\n",
    "- The dog stages are spelt differently in the text\n",
    "\n",
    "#### Image_predictions\n",
    "- Non-descriptive column names (p1,p2)etc\n",
    "- Non- Uniform use of the letter case in p1,p2,p3\n",
    "- Wrong data tyoe in the tweet_id column\n",
    "- Create a column for image_prediction and another for confidence level\n",
    "- Drop unwanted columns e.g p1,p2,p3\n",
    "\n",
    "#### Tweet_json\n",
    "- Use Original Tweets only for analysis\n",
    "- wrong data type in the tweet_id column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidiness Issues\n",
    "- Merge the three datasets together\n",
    "- Stages of the dogs doesnt follow the rule of Tidiness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I dropped the columns that arent needed for the analysis\n",
    "- I changed the timestamp datatype format\n",
    "- I created a single column for the dog_stages\n",
    "- I extracted the sources of the tweets from  the a tag\n",
    "- since the name column contains words that arent name I set them to none\n",
    "- I renamed the cofusing names in the image_predictions table \n",
    "- I extracted the highest confidence level as well as their corresponding breed name and dropped the old column \n",
    "- I finally merged the three datasets togther which conatained 1658 rows and 17 columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
